{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and initialization\n",
    "import sys\n",
    "sys.path.append('..')  # Add the parent directory to the Python path\n",
    "import pandas as pd\n",
    "from pipeline import Pipeline\n",
    "from src.classification_manager import ClassificationManager\n",
    "from utils.file_handler import FileHandler\n",
    "from utils.logger import logger\n",
    "from utils.config_loader import config\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "\n",
    "pipeline = Pipeline()\n",
    "file_handler = FileHandler()\n",
    "classification_manager = ClassificationManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Run the pipeline\n",
    "pipeline_results = pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Process and classify items\n",
    "# Process new items\n",
    "results = classification_manager.process_new_items(pipeline_results)\n",
    "\n",
    "# Classify items\n",
    "classified_items = classification_manager.classify_items(results)\n",
    "\n",
    "# Write results to CSV\n",
    "file_handler.write_results([item['item'] for item in classified_items], classified_items, \"Classified Items\")\n",
    "\n",
    "print(\"Classification process completed. Results have been written to CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mou97\\anaconda3\\envs\\classifier\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "\u001b[32m2024-09-09 23:42:13,767 - utils.logger - INFO - Loading embedding model: sentence-transformers/paraphrase-multilingual-mpnet-base-v2\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:16,338 - utils.logger - INFO - Embedding model loaded successfully\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:16,339 - utils.logger - INFO - Loading embedding model: sentence-transformers/paraphrase-multilingual-mpnet-base-v2\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:18,456 - utils.logger - INFO - Embedding model loaded successfully\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:18,457 - utils.logger - INFO - Initializing vector store with collection: specification_book_collection\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:18,656 - utils.logger - INFO - Initialized vector store at chroma_db with collection specification_book_collection\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:18,658 - utils.logger - INFO - Loading embedding model: sentence-transformers/paraphrase-multilingual-mpnet-base-v2\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:20,725 - utils.logger - INFO - Embedding model loaded successfully\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:20,727 - utils.logger - INFO - Loading embedding model: sentence-transformers/paraphrase-multilingual-mpnet-base-v2\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:22,925 - utils.logger - INFO - Embedding model loaded successfully\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:22,927 - utils.logger - INFO - Initializing vector store with collection: specification_book_collection\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:22,933 - utils.logger - INFO - Initialized vector store at chroma_db with collection specification_book_collection\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:22,934 - utils.logger - INFO - Starting pipeline execution\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:22,936 - utils.logger - INFO - Resetting vector store\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:22,937 - utils.logger - INFO - Resetting vector store\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:22,938 - utils.logger - INFO - Removed existing vector store at chroma_db\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:22,940 - utils.logger - INFO - Initializing vector store with collection: specification_book_collection\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:22,944 - utils.logger - INFO - Initialized vector store at chroma_db with collection specification_book_collection\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:22,945 - utils.logger - INFO - Starting document processing from: data/specifications/\u001b[0m\n",
      "Processing documents:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[32m2024-09-09 23:42:22,949 - utils.logger - INFO - Processing file: Telegram_DSA _eporting.pdf\u001b[0m\n",
      "Processing documents:   0%|          | 0/1 [00:07<?, ?it/s, Chunks=26]\u001b[32m2024-09-09 23:42:30,673 - utils.logger - INFO - Successfully processed Telegram_DSA _eporting.pdf, extracted 26 chunks\u001b[0m\n",
      "Processing documents: 100%|██████████| 1/1 [00:07<00:00,  7.73s/it, Chunks=26]\n",
      "\u001b[32m2024-09-09 23:42:30,679 - utils.logger - INFO - Total processed chunks: 26\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:30,681 - utils.logger - INFO - Processed 26 documents\u001b[0m\n",
      "Processing batches:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[32m2024-09-09 23:42:39,676 - utils.logger - INFO - Storing 26 documents in ChromaDB collection 'specification_book_collection'\u001b[0m\n",
      "Encoding texts: 100%|██████████| 1/1 [00:08<00:00,  8.65s/it]\n",
      "\u001b[32m2024-09-09 23:42:48,360 - utils.logger - INFO - Stored 26 documents in ChromaDB collection 'specification_book_collection'\u001b[0m\n",
      "Processing batches: 100%|██████████| 1/1 [00:17<00:00, 17.67s/it]\n",
      "\u001b[32m2024-09-09 23:42:48,364 - utils.logger - INFO - Document processing and storage completed successfully\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:48,365 - utils.logger - INFO - Verifying document storage\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:48,368 - utils.logger - INFO - Total documents in storage: 26\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:48,370 - utils.logger - INFO - Performing similarity search for query: sample query for verification\u001b[0m\n",
      "Encoding texts: 100%|██████████| 1/1 [00:00<00:00, 10.52it/s]\n",
      "\u001b[32m2024-09-09 23:42:48,471 - utils.logger - INFO - Retrieved 5 sample documents:\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:48,472 - utils.logger - INFO - Sample 1:\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:48,473 - utils.logger - INFO - Content: \n",
      " \n",
      " \n",
      "  For      each      piece      of      content,      submit      report      as      per      ...\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:48,473 - utils.logger - INFO - Metadata: {'chunk_number': 1, 'chunk_type': 'para', 'source': 'data/specifications/Telegram_DSA _eporting.pdf'}\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:48,475 - utils.logger - INFO - Similarity Score: 11.709224700927734\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:48,476 - utils.logger - INFO - Sample 2:\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:48,477 - utils.logger - INFO - Content: \n",
      " \n",
      " \n",
      "  Gather      content      for      the      relevant      channel      using      “DSA      re...\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:48,478 - utils.logger - INFO - Metadata: {'chunk_number': 0, 'chunk_type': 'para', 'source': 'data/specifications/Telegram_DSA _eporting.pdf'}\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:48,479 - utils.logger - INFO - Similarity Score: 12.629535675048828\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:48,480 - utils.logger - INFO - Sample 3:\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:48,481 - utils.logger - INFO - Content: \n",
      " \n",
      " \n",
      "  Include      these   \n",
      " \n",
      "3      things      in      each      report....\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:48,482 - utils.logger - INFO - Metadata: {'chunk_number': 2, 'chunk_type': 'para', 'source': 'data/specifications/Telegram_DSA _eporting.pdf'}\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:48,483 - utils.logger - INFO - Similarity Score: 13.064062118530273\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:48,484 - utils.logger - INFO - Sample 4:\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:48,485 - utils.logger - INFO - Content: \n",
      "a.      Brief      description      of      the      violative      content...\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:48,486 - utils.logger - INFO - Metadata: {'chunk_number': 3, 'chunk_type': 'list_item', 'source': 'data/specifications/Telegram_DSA _eporting.pdf'}\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:48,487 - utils.logger - INFO - Similarity Score: 13.268587112426758\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:48,488 - utils.logger - INFO - Sample 5:\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:48,489 - utils.logger - INFO - Content: \n",
      " \n",
      " \n",
      "  ENG&toc=OJ%3AL%3A2022%3A086%3AT      OC),  \n",
      " \n",
      "  Reason:      The      Houthis      are      a...\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:48,490 - utils.logger - INFO - Metadata: {'chunk_number': 6, 'chunk_type': 'para', 'source': 'data/specifications/Telegram_DSA _eporting.pdf'}\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:48,492 - utils.logger - INFO - Similarity Score: 13.621179580688477\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:48,493 - utils.logger - INFO - Storage verification completed\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available columns:\n",
      "1. link\n",
      "2. description\n",
      "3. primary_classification\n",
      "4. explanation\n",
      "5. formatted_report\n",
      "6. cleaned_report\n",
      "7. reported\n",
      "8. screen_ref\n",
      "9. account\n",
      "10. Column1\n",
      "11. len_cleaned_report\n",
      "12. Unnamed: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-09 23:42:53,844 - utils.logger - INFO - Read 9 rows from data/input/127_classified (2).csv\u001b[0m\n",
      "\u001b[32m2024-09-09 23:42:53,845 - utils.logger - INFO - Chosen column: description\u001b[0m\n",
      "Encoding texts: 100%|██████████| 1/1 [00:00<00:00,  4.14it/s]<?, ?it/s]\n",
      "\u001b[32m2024-09-09 23:42:54,095 - utils.logger - INFO - Performing similarity search for query: A statement by the US-designated terrorist group, Ansar Allah, locally known as Houthis caliming responsibility for attacking an American Navy vessel (Maersk Yorktown). This account shared the statement to glorify this terrorist activity and promote for it.\u001b[0m\n",
      "Encoding texts: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s]\n",
      "Encoding texts: 100%|██████████| 1/1 [00:00<00:00,  4.54it/s]<03:45, 28.23s/it]\n",
      "\u001b[32m2024-09-09 23:43:22,306 - utils.logger - INFO - Performing similarity search for query: A statement by the US-designated terrorist group, Ansar Allah, locally known as Houthis caliming responsibility for attacking an Israeli commercial vessel (MSC Darwin) in the Eden Sea. This account shared the statement to glorify this terrorist activity and promote for it.\u001b[0m\n",
      "Encoding texts: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s]\n",
      "Encoding texts: 100%|██████████| 1/1 [00:00<00:00,  4.39it/s]<01:27, 12.56s/it]\n",
      "\u001b[32m2024-09-09 23:43:23,897 - utils.logger - INFO - Performing similarity search for query: A statement by the US-designated terrorist group, Ansar Allah, locally known as Houthis caliming responsibility for attacking a British commercial vessel (Andromeda Star) in the Red Sea. This account shared the statement to glorify this terrorist activity and promote for it.\u001b[0m\n",
      "Encoding texts: 100%|██████████| 1/1 [00:00<00:00,  4.44it/s]\n",
      "Encoding texts: 100%|██████████| 1/1 [00:00<00:00,  5.88it/s]<00:45,  7.58s/it]\n",
      "\u001b[32m2024-09-09 23:43:25,492 - utils.logger - INFO - Performing similarity search for query: A statement by the US-designated terrorist group Ansar Allah, locally known as Houthis, claiming responsibility for attacking an Israeli commercial vessel in the Indian Ocean.\u001b[0m\n",
      "Encoding texts: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s]\n",
      "Encoding texts: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s]<00:26,  5.24s/it]\n",
      "\u001b[32m2024-09-09 23:43:27,120 - utils.logger - INFO - Performing similarity search for query: A group of pictures with banners calling for death to Israel, the US, and the Jews.\u001b[0m\n",
      "Encoding texts: 100%|██████████| 1/1 [00:00<00:00,  7.68it/s]\n",
      "Encoding texts: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s]<00:16,  4.03s/it]\n",
      "\u001b[32m2024-09-09 23:43:29,073 - utils.logger - INFO - Performing similarity search for query: A statement by the US-designated terrorist group, Ansar Allah, locally known as Houthis, claimed to attacks commercial vessal called (Carysail) in the Red Sea on July 12, 2024. This statement is published to promote for the terrorist group and spread its propaganda.\u001b[0m\n",
      "Encoding texts: 100%|██████████| 1/1 [00:00<00:00,  4.59it/s]\n",
      "Encoding texts: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s]<00:09,  3.22s/it]\n",
      "\u001b[32m2024-09-09 23:43:30,691 - utils.logger - INFO - Performing similarity search for query: A post glorifying the US-designated terrorist Abdul Malik Al-Houthi (featured in the picture), leader of the US-designated terrorist group Ansar Allah, locally known as Houthis.\u001b[0m\n",
      "Encoding texts: 100%|██████████| 1/1 [00:00<00:00,  4.35it/s]\n",
      "Encoding texts: 100%|██████████| 1/1 [00:00<00:00,  4.92it/s]<00:05,  2.76s/it]\n",
      "\u001b[32m2024-09-09 23:43:32,531 - utils.logger - INFO - Performing similarity search for query: A statement by the US-designated terrorist group, Ansar Allah, locally known as Houthis, claimed to attacks commercial vessels in the Red Sea on July 27, 2024. This statement is published to promote the terrorist group and spread its propaganda.\u001b[0m\n",
      "Encoding texts: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s]\n",
      "Encoding texts: 100%|██████████| 1/1 [00:00<00:00,  5.39it/s]<00:02,  2.39s/it]\n",
      "\u001b[32m2024-09-09 23:43:34,112 - utils.logger - INFO - Performing similarity search for query: A post glorifying the US-designated terrorist Abdul Malik Al-Houthi (featured in the picture), leader of the US-designated terrorist group Ansar Allah, locally known as Houthis.\u001b[0m\n",
      "Encoding texts: 100%|██████████| 1/1 [00:00<00:00,  5.58it/s]\n",
      "Processing and classifying items: 100%|██████████| 9/9 [00:41<00:00,  4.65s/it]\n",
      "\u001b[32m2024-09-09 23:43:35,681 - utils.logger - INFO - Writing results to data/output/classification_results.csv\u001b[0m\n",
      "\u001b[32m2024-09-09 23:43:35,684 - utils.logger - INFO - Results successfully written to data/output/classification_results.csv\u001b[0m\n",
      "\u001b[32m2024-09-09 23:43:35,685 - utils.logger - INFO - Successfully classified 9 items\u001b[0m\n",
      "\u001b[32m2024-09-09 23:43:35,686 - utils.logger - INFO - Pipeline execution completed successfully\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classified 9 items.\n",
      "\n",
      "Sample results:\n",
      "\n",
      "Item: A statement by the US-designated terrorist group, ...\n",
      "Primary Classification: Terrorist Content\n",
      "Overall Classification: Terrorist Content\n",
      "Confidence: 0.95\n",
      "\n",
      "Item: A statement by the US-designated terrorist group, ...\n",
      "Primary Classification: Terrorist Content\n",
      "Overall Classification: Terrorist Content\n",
      "Confidence: 0.95\n",
      "\n",
      "Item: A statement by the US-designated terrorist group, ...\n",
      "Primary Classification: Terrorist Content\n",
      "Overall Classification: Terrorist Content\n",
      "Confidence: 0.95\n",
      "\n",
      "Item: A statement by the US-designated terrorist group A...\n",
      "Primary Classification: Terrorist Content\n",
      "Overall Classification: Terrorist Content\n",
      "Confidence: 0.95\n",
      "\n",
      "Item: A group of pictures with banners calling for death...\n",
      "Primary Classification: Hate Speech\n",
      "Overall Classification: Hate Speech\n",
      "Confidence: 0.95\n",
      "\n",
      "Classification process completed. Results have been written to CSV.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and initialization\n",
    "import sys\n",
    "sys.path.append('..')  # Add the parent directory to the Python path\n",
    "from pipeline import Pipeline\n",
    "from utils.logger import logger\n",
    "from utils.config_loader import config\n",
    "\n",
    "# Initialize the pipeline\n",
    "pipeline = Pipeline()\n",
    "\n",
    "# Cell 2: Run the pipeline\n",
    "classified_items = pipeline.run()\n",
    "\n",
    "# Print a summary of the results\n",
    "print(f\"\\nClassified {len(classified_items)} items.\")\n",
    "print(\"\\nSample results:\")\n",
    "for item in classified_items[:5]:  # Print first 5 results\n",
    "    print(f\"\\nItem: {item['item'][:50]}...\")\n",
    "    print(f\"Primary Classification: {item['primary_classification']}\")\n",
    "    print(f\"Overall Classification: {item['classification']}\")\n",
    "    print(f\"Confidence: {item['confidence']}\")\n",
    "\n",
    "print(\"\\nClassification process completed. Results have been written to CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi3.5:3.8b-mini-instruct-q8_0\n",
      "llama3.1:8b-instruct-q8_0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def list_ollama_models():\n",
    "    response = requests.get('http://localhost:11434/api/tags')\n",
    "    if response.status_code == 200:\n",
    "        return [model['name'] for model in response.json()['models']]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "models = list_ollama_models()\n",
    "for model in models:\n",
    "    print(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
